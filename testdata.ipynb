{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import open3d as o3d\n",
    "import numpy as np  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['coord', 'grid_coord', 'segment', 'offset_vector', 'offset', 'feat', 'batch', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key'])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(-1.3277, device='cuda:0')\n",
      "feat (2520, 64) [[ 1.8150625  -0.21156877 -0.6854651  ... -0.9145881   3.6848195\n",
      "  -0.67851233]\n",
      " [ 2.6054084  -0.27915195 -0.48477268 ... -0.09085202  3.699931\n",
      "  -0.71023357]\n",
      " [ 4.3451834  -2.056975    1.7662511  ... -1.3247106   6.4151497\n",
      "  -1.5648804 ]\n",
      " ...\n",
      " [ 1.7546022   0.96389043  0.9208914  ... -0.02010047  0.846984\n",
      "  -1.8479385 ]\n",
      " [ 1.1326145  -0.501377    1.7411212  ...  0.10290253 -0.4396162\n",
      "  -1.7515671 ]\n",
      " [ 1.7888358   0.07827127  1.4333152  ... -0.5393679  -0.23504615\n",
      "  -1.3325466 ]]\n",
      "[[ 0.23419605 -0.86805135 -0.59151775]\n",
      " [ 0.24591915 -0.79034305 -0.09641358]\n",
      " [ 0.21403874 -0.59407777  0.2598418 ]\n",
      " ...\n",
      " [ 0.2530775   0.7718995  -0.36538458]\n",
      " [ 0.29401678  0.721824   -0.25102797]\n",
      " [ 0.2886094   0.72910786 -0.36708003]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.00545434  0.05848154 -0.01578385]\n",
      " ...\n",
      " [-0.8421338  -0.18966074 -1.3782363 ]\n",
      " [-0.8421338  -0.18966074 -1.3782363 ]\n",
      " [-0.8421338  -0.18966074 -1.3782363 ]]\n",
      "[[ 0.23419605 -0.86805135 -0.59151775]\n",
      " [ 0.24591915 -0.79034305 -0.09641358]\n",
      " [ 0.20858441 -0.53559625  0.24405795]\n",
      " ...\n",
      " [-0.5890563   0.5822388  -1.7436209 ]\n",
      " [-0.54811704  0.53216326 -1.6292642 ]\n",
      " [-0.55352443  0.5394471  -1.7453163 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./pointdata.pth', 'rb') as file: \n",
    "    loaded_data = torch.load(file)\n",
    "    point = loaded_data\n",
    "    \n",
    "    print(loaded_data.keys())\n",
    "    print(type(loaded_data['coord'][0][0]))\n",
    "    # print(type(loaded_data['normal'][0][0]))\n",
    "    # loaded_data['labels'] = loaded_data['labels'].astype(int) \n",
    "    # print(type(loaded_data['labels'][0]))\n",
    "    print(torch.min(loaded_data['coord']))\n",
    "    \n",
    "    # mask = np.full(loaded_data['coord'].shape[0], False, dtype=bool)  \n",
    "  \n",
    "    # 计算需要设置为 True 的元素数量  \n",
    "    # num_true = mask.size // 10  # 十分之一的元素数量  \n",
    "    \n",
    "    # 随机选择位置并将其设为 True  \n",
    "    # indices = np.random.choice(mask.size, num_true, replace=False)  \n",
    "    # mask = mask.flatten()  \n",
    "    # mask[indices] = True  \n",
    "    # mask = mask.reshape(loaded_data['coord'].shape[0]) \n",
    "    # print(mask.shape,mask)\n",
    "    \n",
    "    mask = (loaded_data['segment'] != 0).cpu().numpy()\n",
    "    feat = loaded_data['feat'].cpu().detach().numpy()\n",
    "    print('feat',feat.shape,feat)\n",
    "    coord = loaded_data['coord'].cpu().numpy()\n",
    "    print(coord)\n",
    "    offset = loaded_data['offset_vector'].cpu().detach().numpy()\n",
    "    print(offset)\n",
    "    # points = coord\n",
    "    # points[mask] = coord[mask]+offset[mask]\n",
    "    points = coord+offset\n",
    "    print(points)\n",
    "    point_cloud = o3d.geometry.PointCloud()  \n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord torch.Size([1960, 3]) tensor([[ 0.4257, -0.5839, -0.6326],\n",
      "        [ 0.4318, -0.5143, -0.2401],\n",
      "        [ 0.4347, -0.5247, -0.2558],\n",
      "        ...,\n",
      "        [ 0.4775,  0.8250, -0.8549],\n",
      "        [ 0.4954,  0.9436, -0.0997],\n",
      "        [ 0.4552,  0.9401, -0.1067]], device='cuda:0')\n",
      "grid_coord torch.Size([1960, 3]) tensor([[31,  4,  5],\n",
      "        [31,  5, 13],\n",
      "        [31,  5, 12],\n",
      "        ...,\n",
      "        [32, 32,  0],\n",
      "        [32, 34, 16],\n",
      "        [32, 34, 15]], device='cuda:0')\n",
      "segment torch.Size([1960]) tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "offset_vector torch.Size([1960, 3]) tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.9993, -1.7156,  0.2347],\n",
      "        [ 0.9993, -1.7156,  0.2347],\n",
      "        [ 0.9993, -1.7156,  0.2347]], device='cuda:0')\n",
      "offset torch.Size([1]) tensor([1960], device='cuda:0')\n",
      "feat torch.Size([1960, 64]) tensor([[ 1.5956, -0.8234, -0.1293,  ...,  0.0142,  2.0401, -0.6389],\n",
      "        [ 1.5775, -1.1537, -0.7662,  ..., -1.4262,  2.3399, -0.2684],\n",
      "        [ 1.0667, -1.2319,  0.0862,  ..., -1.2243,  1.9843, -0.6124],\n",
      "        ...,\n",
      "        [ 3.2860,  0.1745,  2.4465,  ..., -0.4822,  2.2281, -1.4853],\n",
      "        [ 3.0526, -0.3340,  2.5949,  ...,  0.2994,  0.5407,  0.1338],\n",
      "        [ 1.3520, -0.4807,  2.0755,  ..., -1.4235,  0.5403, -2.0090]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "batch torch.Size([1960]) tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "serialized_code torch.Size([4, 1960]) tensor([[ 15068,  14555,  14556,  ..., 131072, 161962, 132949],\n",
      "        [  9683,  10199,  10198,  ..., 196608, 200736, 197225],\n",
      "        [  4938,   5453,   5450,  ..., 131072, 161946, 132965],\n",
      "        [ 18917,  19431,  19430,  ..., 196608, 200720, 197209]],\n",
      "       device='cuda:0')\n",
      "serialized_order torch.Size([4, 1960]) tensor([[1261, 1176, 1146,  ..., 1456, 1452, 1445],\n",
      "        [1261, 1146, 1176,  ..., 1896, 1756, 1696],\n",
      "        [1261, 1333, 1334,  ...,  247,   63,   59],\n",
      "        [1261, 1388, 1343,  ..., 1701, 1756, 1696]], device='cuda:0')\n",
      "serialized_inverse torch.Size([4, 1960]) tensor([[ 346,  344,  345,  ..., 1416, 1455, 1431],\n",
      "        [ 193,  207,  206,  ..., 1918, 1956, 1927],\n",
      "        [  43,   60,   59,  ..., 1878, 1911, 1908],\n",
      "        [ 575,  589,  588,  ..., 1918, 1951, 1926]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m point\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserialized_depth\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(key,\u001b[43mpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m,point[key])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for key in point.keys():\n",
    "    if key != 'serialized_depth':\n",
    "        print(key,point[key].shape,point[key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0055,  0.0585, -0.0158],\n",
      "        ...,\n",
      "        [-0.8421, -0.1897, -1.3782],\n",
      "        [-0.8421, -0.1897, -1.3782],\n",
      "        [-0.8421, -0.1897, -1.3782]], device='cuda:0')\n",
      "tensor([[ 0.1000,  0.0000,  0.0000],\n",
      "        [ 0.1000,  0.0000,  0.0000],\n",
      "        [ 0.0945,  0.0585, -0.0158],\n",
      "        ...,\n",
      "        [-0.7421, -0.1897, -1.3782],\n",
      "        [-0.7421, -0.1897, -1.3782],\n",
      "        [-0.7421, -0.1897, -1.3782]], device='cuda:0')\n",
      "tensor([[    nan,     nan,     nan],\n",
      "        [    nan,     nan,     nan],\n",
      "        [-0.0897,  0.9616, -0.2595],\n",
      "        ...,\n",
      "        [-0.5178, -0.1166, -0.8475],\n",
      "        [-0.5178, -0.1166, -0.8475],\n",
      "        [-0.5178, -0.1166, -0.8475]], device='cuda:0')\n",
      "tensor([[ 1.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000],\n",
      "        [ 0.8420,  0.5208, -0.1406],\n",
      "        ...,\n",
      "        [-0.4707, -0.1203, -0.8741],\n",
      "        [-0.4707, -0.1203, -0.8741],\n",
      "        [-0.4707, -0.1203, -0.8741]], device='cuda:0')\n",
      "tensor([False, False,  True,  ...,  True,  True,  True], device='cuda:0')\n",
      "loss dir tensor(0.0002, device='cuda:0')\n",
      "tensor(0.0034, device='cuda:0')\n",
      "tensor(0.0033, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 计算dir loss\n",
    "offset_logits = point['offset_vector']\n",
    "offset_target = offset_logits.clone()\n",
    "offset_target[:,0] = offset_logits[:,0] + 0.1\n",
    "\n",
    "print(offset_logits)\n",
    "print(offset_target)\n",
    "offset_pred_norm = torch.norm(offset_logits,dim=1).view(-1,1)\n",
    "offset_pred_dir = torch.div(offset_logits, offset_pred_norm)\n",
    "mask1 = offset_pred_norm > 0.01\n",
    "print(offset_pred_dir)\n",
    "offset_target_norm = torch.norm(offset_target, dim=1).view(-1,1)\n",
    "offset_target_dir = torch.div(offset_target, offset_target_norm)\n",
    "mask2 = offset_target_norm > 0.01\n",
    "mask = mask1 & mask2\n",
    "mask = mask.squeeze()\n",
    "\n",
    "print(offset_target_dir)\n",
    "print(mask)\n",
    "dir_mat = torch.sum(offset_pred_dir * offset_target_dir, dim=1)\n",
    "dir_mat = dir_mat - 1\n",
    "dir_mat = dir_mat * dir_mat\n",
    "loss_dir = torch.div(torch.sum(dir_mat[mask]),mask.shape[0])\n",
    "print('loss dir',loss_dir)\n",
    "\n",
    "cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6) \n",
    "loss = 1 - cos_sim(offset_logits, offset_target)\n",
    "print(loss.mean())\n",
    "\n",
    "loss = nn.MSELoss()(offset_logits,offset_target)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading file data/0: invalid header or archive is corrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./testdata.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[0;32m----> 2\u001b[0m     loaded_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loaded_data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loaded_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid_coord\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/ptv3/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ptv3/lib/python3.8/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ptv3/lib/python3.8/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/ptv3/lib/python3.8/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading file data/0: invalid header or archive is corrupted"
     ]
    }
   ],
   "source": [
    "with open('./testdata.pth', 'rb') as file: \n",
    "    loaded_data = torch.load(file)\n",
    "    print(loaded_data.keys())\n",
    "    print(loaded_data['grid_coord'])\n",
    "    print(loaded_data['offset'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
